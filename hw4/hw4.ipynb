{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Let $f(x) = \\frac{1}{x} - d$. We want to solve $f(x) = 0$.\n",
    "\n",
    "The Newton iteration to solve this equation is \n",
    "$$\n",
    "x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n",
    "$$\n",
    "with an initial value $x_0$.\n",
    "\n",
    "Because $f'(x) = -1/x^2$, we have\n",
    "$$\n",
    "x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)} = x_k - \\frac{\\frac{1}{x_k} - d}{-1/x_k^2} = x_k (2 - d x_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a julia function for this Newton iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newtonDivision (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function newtonDivision(d, x0; maxIts=20, optTol=1e-6)\n",
    "    xn = x0\n",
    "    xnp = x0\n",
    "    for i = 1:maxIts\n",
    "        xn = xnp\n",
    "        xnp = xn * (2-d*xn)\n",
    "        println(\"x\", i, \" = \", xnp)\n",
    "        if abs(xnp-xn) < optTol \n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    return xnp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 = 0.3553546354386859\n",
      "x2 = 0.3674530222388057\n",
      "x3 = 0.3678789468978142\n",
      "x4 = 0.36787944117077825\n"
     ]
    }
   ],
   "source": [
    "e_inverse = newtonDivision(e, 0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $x_0 = 0.3$, $e^{-1} \\approx 0.367879$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 = -0.7182818284590451\n",
      "x2 = -2.8390034982193373\n",
      "x3 = -27.5871977825187\n",
      "x4 = -2123.932244789702\n",
      "x5 = -1.2266656892003369e7\n",
      "x6 = -4.090222597171767e14\n",
      "x7 = -4.5476639958844456e29\n",
      "x8 = -5.621746013750638e59\n",
      "x9 = -8.590865567938277e119\n",
      "x10 = -2.0061727551660916e240\n",
      "x11 = -Inf\n",
      "x12 = -Inf\n",
      "x13 = -Inf\n",
      "x14 = -Inf\n",
      "x15 = -Inf\n",
      "x16 = -Inf\n",
      "x17 = -Inf\n",
      "x18 = -Inf\n",
      "x19 = -Inf\n",
      "x20 = -Inf\n"
     ]
    }
   ],
   "source": [
    "e_inverse_bad = newtonDivision(e, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $x_0 = 1$, $x_k$ does not converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a)\n",
    "\n",
    "Let $f(x) = x^q$ where $q$ is an integer greater than 2.\n",
    "\n",
    "The Newton method to solve $f(x) = 0$ is\n",
    "\n",
    "\\begin{align*}\n",
    "x_{k+1} & = x_k - \\frac{f(x_k)}{f'(x_k)} \\\\\n",
    " & = x_k - \\frac{f(x_k)}{f'(x_k)} \\\\\n",
    " & = x_k - \\frac{x_k^q}{qx_k^{q-1}} \\\\\n",
    " & = (1-\\frac{1}{q}) x_k \\\\\n",
    "\\end{align*}\n",
    "Therefore, \n",
    "$$\n",
    "\\frac{\\|x_{k+1} - x^* \\|}{\\| x_k - x^* \\|} \\leq (1-\\frac{1}{q}) \\qquad \\text{ for all }k = 0, 1, \\dots\n",
    "$$\n",
    "The sequence converges Q-linearly with convergence ratio $(1-\\frac{1}{q})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(c)\n",
    "\n",
    "Let $f(x) = \\| x \\|_2^\\beta$ wheter $\\beta > 1$\n",
    "\n",
    "Then \n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_i} f(x) = \\beta (\\sum_{i=1}^n x_i^2)^{\\frac{\\beta-2}{2}} x_i\n",
    "$$\n",
    "hence,\n",
    "$$\n",
    "\\nabla f(x) = \\beta \\| x \\|_2^{\\beta-2} x\n",
    "$$\n",
    "\n",
    "Also,\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_i} \\frac{\\partial}{\\partial x_i} f(x) = \\beta (\\beta-2) \\| x \\|_2^{\\beta-4} x_i^2 + \\beta \\| x \\|_2^{\\beta-2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_j} \\frac{\\partial}{\\partial x_i} f(x) = \\beta (\\beta-2) \\| x \\|_2^{\\beta-4} x_i x_j \\qquad i \\neq j\n",
    "$$\n",
    "hence,\n",
    "$$\n",
    "\\nabla^2 f(x) = \\beta(\\beta-2) \\| x \\|_2^{\\beta-4} x x' + \\beta \\| x \\|_2^{\\beta - 2} I = \\beta(\\beta-2) \\| x \\|_2^{\\beta-4} (xx' + \\frac{\\| x \\|_2^2}{ \\beta - 2 } I )\n",
    "$$\n",
    "\n",
    "Then, by the formula $(A + CBC')^{-1} = A^{-1} - A^{-1} C (B^{-1} + C' A^{-1} C)^{-1} C' A^{-1} $, we have\n",
    "$$\n",
    "(\\nabla^2 f(x))^{-1} = \\frac{1}{\\beta \\| x \\|_2^{\\beta-2}} (I - \\frac{\\beta-2}{\\beta-1} \\frac{1}{\\| x \\|^2_2} xx')\n",
    "$$\n",
    "\n",
    "On the pure form of Newton's method,\n",
    "\n",
    "\\begin{align*}\n",
    "x_{k+1} & = x_k - (\\nabla^2 f(x_k))^{-1} \\nabla f(x_k)  \\\\\n",
    "& = x_k - \\frac{1}{\\beta \\| x \\|_2^{\\beta-2}} (I - \\frac{\\beta-2}{\\beta-1} \\frac{1}{\\| x \\|^2_2} xx') \\beta \\| x \\|_2^{\\beta-2} x \\\\\n",
    "& = x_k - (x_k - \\frac{\\beta - 2}{\\beta - 1}x_k ) \\\\\n",
    "& = \\frac{\\beta - 2}{ \\beta - 1} x_k\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, \n",
    "$$\n",
    "\\frac{\\| x_{k+1} - x^* \\|_2}{ \\| x_k - x^* \\|_2 } = \\frac{| \\beta - 2 |}{ | \\beta - 1 |} \\text{ for all } k\n",
    "$$\n",
    "where $\\beta \\neq 1$.\n",
    "\n",
    "The sequence converges if \n",
    "$$\n",
    "\\frac{| \\beta - 2 |}{ | \\beta - 1 |} < 1\n",
    "$$\n",
    "\n",
    "For $\\beta > 2$\n",
    "$$\n",
    "\\frac{| \\beta - 2 |}{ | \\beta - 1 |} < 1 \\Leftrightarrow \\frac{ \\beta - 2 }{ \\beta - 1 } < 1 \\Leftrightarrow 1 < 2 \n",
    "$$\n",
    "Therefore, for $\\beta > 2$, the sequence converges.\n",
    "\n",
    "For $\\beta = 2$\n",
    "$$\n",
    "\\frac{| \\beta - 2 |}{ | \\beta - 1 |} = 0\n",
    "$$\n",
    "Therefore, for $\\beta = 2$, the sequence converges superlinear.\n",
    "\n",
    "\n",
    "For $1 < \\beta < 2$\n",
    "$$\n",
    "\\frac{| \\beta - 2 |}{ | \\beta - 1 |} < 1 \\Leftrightarrow \\frac{ 2 - \\beta }{ \\beta - 1 } < 1 \\Leftrightarrow \\beta > \\frac{3}{2}\n",
    "$$\n",
    "Therefore, for $1 < \\beta < 2$, the sequence converges if $\\beta > \\frac{3}{2}$.\n",
    "\n",
    "For $\\beta < 1$\n",
    "$$\n",
    "\\frac{| \\beta - 2 |}{ | \\beta - 1 |} < 1 \\Leftrightarrow \\frac{ 2 - \\beta }{ 1 - \\beta } < 1 \\Leftrightarrow 2 < 1 \\quad \\text{(impossible!)}\n",
    "$$\n",
    "Therefore, for $\\beta < 1$, the sequence does not converge.\n",
    "\n",
    "For $\\beta = 1$,\n",
    "$$\\nabla^2 f(x) = \\frac{1}{\\| x \\|_2} (-\\frac{1}{\\| x \\|^2_2} xx' + I)$$\n",
    "It is not inverible, because\n",
    "$$\n",
    "(\\nabla^2 f(x)) x = \\frac{1}{\\| x \\|_2} (-\\frac{1}{\\| x \\|^2_2} xx'x + x) = \\frac{1}{\\| x \\|_2} (-x + x) = 0 \\qquad \\text{ for any } x\n",
    "$$\n",
    "In this case, Newton's method is not applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2(b)\n",
    "\n",
    "Newton's method with Armijo linesearch\n",
    "\n",
    "\\begin{align*}\n",
    "x_{k+1} & = x_k - \\alpha_k (\\nabla^2 f(x_k))^{-1} \\nabla f(x_k)  \\\\\n",
    "& = x_k - \\alpha_k \\frac{1}{\\beta \\| x \\|_2^{\\beta-2}} (I - \\frac{\\beta-2}{\\beta-1} \\frac{1}{\\| x \\|^2_2} xx') \\beta \\| x \\|_2^{\\beta-2} x \\\\\n",
    "& = x_k - \\alpha_k ( x_k - \\frac{\\beta-2}{\\beta-1} x_k ) \\\\\n",
    "& = ( 1 - \\alpha_k (1 - \\frac{\\beta-2}{\\beta-1}) ) x_k \\\\\n",
    "& = ( 1 -  \\frac{\\alpha_k}{\\beta - 1} ) x_k \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Armijo linesearch requires that\n",
    "\n",
    "\\begin{align*}\n",
    "f(x_k + \\alpha_k d_k) - f(x_k) & \\leq \\mu \\alpha_k \\nabla f(x_k)^T d_k \\\\\n",
    "f((1 - \\frac{\\alpha_k}{\\beta - 1}) x_k) - f(x_k) & \\leq  \\mu \\alpha_k \\beta \\| x \\|^{\\beta - 2}_2 x' (-(1-\\frac{\\beta-2}{\\beta-1}) x_k ) \\\\\n",
    "| (1 - \\frac{\\alpha_k}{\\beta - 1}) |^\\beta \\| x_k \\|_2^\\beta - \\| x_k \\|_2^\\beta & \\leq \\mu \\alpha_k \\beta \\| x_k \\|_2^\\beta ( - (1 - \\frac{\\beta-2}{\\beta-1})) \\\\\n",
    "| 1 - \\frac{\\alpha_k}{\\beta-1} |^\\beta - 1 & \\leq \\mu \\alpha_k \\frac{-\\beta}{\\beta-1} \\\\\n",
    "\\alpha_k & \\leq \\frac{1 - | 1 - \\frac{\\alpha_k}{\\beta-1} |^\\beta}{\\mu \\frac{\\beta}{\\beta-1}} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now, suppose $\\beta > 1$, then the condition can be written as\n",
    "\\begin{align*}\n",
    "\\frac{\\alpha_k}{\\beta-1} & \\leq \\frac{1 - | 1 - \\frac{\\alpha_k}{\\beta-1} |^\\beta}{\\mu \\beta} \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $x_{k+1} = (1 - \\frac{\\alpha_k}{\\beta-1} )x_k$. \n",
    "\n",
    "If we choose $\\mu$ so that $\\mu = \\frac{1}{\\beta} < 1$, then $\\mu \\beta = 1$.\n",
    "Then the condition becomes\n",
    "\\begin{align*}\n",
    "\\frac{\\alpha_k}{\\beta-1} & \\leq 1 - | 1 - \\frac{\\alpha_k}{\\beta-1} |^\\beta \\\\\n",
    "| 1 - \\frac{\\alpha_k}{\\beta-1} |^\\beta & \\leq 1 - \\frac{\\alpha_k}{\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "In this sense, if we choose $\\alpha_k$ to be small so that $\\frac{\\alpha_k}{\\beta-1} < 1$, then the condition would be satisfied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $\\beta < 1$, then\n",
    "\n",
    "\\begin{align*}\n",
    "f(x_k + \\alpha_k d_k) - f(x_k) & \\leq \\mu \\alpha_k \\nabla f(x_k)^T d_k \\\\\n",
    "\\alpha_k & \\leq \\frac{1 - | 1 - \\frac{\\alpha_k}{\\beta-1} |^\\beta}{\\mu \\frac{\\beta}{\\beta-1}} \\\\\n",
    "\\alpha_k & \\leq \\frac{| 1 + \\frac{\\alpha_k}{1-\\beta} |^\\beta - 1}{ \\mu \\frac{\\beta}{1-\\beta}} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "x_{k+1} & = x_k - \\alpha_k (\\nabla^2 f(x_k))^{-1} \\nabla f(x_k)  \\\\\n",
    "& = ( 1 + \\frac{\\alpha_k}{1 - \\beta} ) x_k \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Consider the cost function $f(x) = x' Q x + b' x$ where $Q$ is symmetric positive definite.\n",
    "\n",
    "Note that $\\nabla f(x) = Qx -b$ and $\\nabla^2 f(x) = Q$ for all $x$\n",
    "\n",
    "We prove it by induction.\n",
    "\n",
    "Firstly,\n",
    "\\begin{align*}\n",
    "D^1 q^0 & = D^0 q^0 + \\frac{y^0 y^{0\\prime}q^0}{q^{0\\prime}y^0} \\\\\n",
    "& = D^0 q^0 + y^0 \\\\\n",
    "& = p^0 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $k$ is such that $D^k q^i = p^i$ for all $i \\leq k-1$.\n",
    "\n",
    "Then \n",
    "\\begin{align}\n",
    "D^{k+1} q^k & = D^k q^k + \\frac{y^k y^{k\\prime}q^k}{q^{k\\prime y^k}} \\\\\n",
    "& = D^k q^k + y^k \\\\\n",
    "& = D^k q^k + (p^k - D^k q^k) \\\\\n",
    "& = p^k\n",
    "\\end{align}\n",
    "\n",
    "Also, for $i < k$,\n",
    "\\begin{align}\n",
    "D^{k+1} q^i & = D^k q^i + \\frac{y^k y^{k\\prime}q^i}{q^{k\\prime y^k}} \\\\\n",
    "& = D^k q^i + \\frac{y^k (p^k - D^k q^k)'q^i}{q^{k\\prime y^k}} \\\\\n",
    "& = D^k q^i + \\frac{y^k (p^{k\\prime} q^i - q^{k\\prime}D^k q^i)}{q^{k\\prime y^k}} \\\\\n",
    "& = p^i + \\frac{y^k (p^{k\\prime} q^i - q^{k\\prime}p^i)}{q^{k\\prime y^k}} \\qquad \\text{ by induction assumption} \\\\\n",
    "& = p^i \\\\\n",
    "\\end{align}\n",
    "becasue $p^{k\\prime} q^i = q^{k\\prime}p^i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why $p^{k\\prime} q^i = q^{k\\prime}p^i$ is that:\n",
    "\n",
    "When $f(x) = x' Q x - b'x$, then $\\nabla f(x) = Q x - b$.\n",
    "\n",
    "Then $q^j = \\nabla f(x^{j+1}) - \\nabla f(x^{j}) = (Q x^{j+1} - b) - (Q x^j - b) = Q p^j$ for all $j$.\n",
    "\n",
    "Therefore, $p^{k\\prime} q^i = p^{k\\prime} Q p^i  = q^{k\\prime}p^i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By mathematical induction, $D^{k+1} q^i = p^i$ for all $k$ and $i \\leq k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $q^0, \\dots, q^{n-1}$ are linearly independent. In particular, the matrix $[q^0 \\cdots q^{n-1}]$ is invertible.\n",
    "\n",
    "Also, $D^{k+1} q^i = p^i$ for all $k$ and $i \\leq k$,\n",
    "\n",
    "we have\n",
    "\\begin{align}\n",
    "D^{n} [q^0 \\cdots q^{n-1}] & = [p^0 \\cdots p^{n-1}] \\\\\n",
    "D^{n} & = [p^0 \\cdots p^{n-1}] [q^0 \\cdots q^{n-1}]^{-1} \\\\\n",
    "\\end{align}\n",
    "\n",
    "On the other hand, because $q^j = \\nabla f(x^{j+1}) - \\nabla f(x^{j}) = (Q x^{j+1} - b) - (Q x^j - b) = Q p^j$, it also have\n",
    "\\begin{align}\n",
    "Q [p^0 \\cdots p^{n-1}] & = [q^0 \\cdots q^{n-1}]  \\\\\n",
    "Q & = [q^0 \\cdots q^{n-1}] [p^0 \\cdots p^{n-1}]^{-1} \\\\\n",
    "\\end{align}\n",
    "\n",
    "$[p^0 \\cdots p^{n-1}]$ is invertible because \n",
    "$[p^0 \\cdots p^{n-1}] = Q^{-1} [q^0 \\cdots q^{n-1}] $ as $Q$ is positive definite.\n",
    "\n",
    "Therefore,\n",
    "$D^{n} = [p^0 \\cdots p^{n-1}] [q^0 \\cdots q^{n-1}]^{-1} = ([q^0 \\cdots q^{n-1}] [p^0 \\cdots p^{n-1}]^{-1})^{-1} = Q^{-1} = (\\nabla^2 f(x))^{-1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Toms566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backTracking (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the Toms566.Problem Type to the objective function format\n",
    "function p2obj(p::Toms566.Problem)\n",
    "    function obj(x)\n",
    "        return (p.obj(x), p.grd(x), p.hes(x))\n",
    "    end\n",
    "    return obj\n",
    "end\n",
    "\n",
    "# Modified Newton method\n",
    "# Modify the eigenvalues to be positive\n",
    "function BkFunInv(H, ε)\n",
    "    D, V = eig(H)\n",
    "    Dp = ifelse(D .> ε, D, ε)\n",
    "    Dpinv = 1./Dp\n",
    "    return V * Diagonal(Dpinv) * V'\n",
    "end\n",
    "\n",
    "# Back tracking method\n",
    "function backTracking(obj, x, d, g)\n",
    "    α = 1\n",
    "    while (obj(x + α*d)[1] > obj(x)[1] + α * 1e-4 * dot(g, d))\n",
    "       α = α * 0.5\n",
    "       if α < 1e-6\n",
    "           break\n",
    "       end\n",
    "    end\n",
    "    return α\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newtmin (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Newton Method\n",
    "function newtmin(obj, x0; maxIts=1000, optTol=1e-6, BkFlag = true, btFlag = true)\n",
    "    # Minimize a function f using Newton’s method.\n",
    "    # obj: a function that evaluates the objective value,\n",
    "    # gradient, and Hessian at a point x, i.e.,\n",
    "    # (f, g, H) = obj(x)\n",
    "    # x0: starting point.\n",
    "    # maxIts (optional): maximum number of iterations.\n",
    "    # optTol (optional): optimality tolerance based on\n",
    "    # ||grad(x)|| <= optTol*||grad(x0)||\n",
    "    # BkFlag (optional): true for doing Modified Hessian\n",
    "    # btFlag (optional): true for doing Back Tracking\n",
    "    f0, g0, H0 = obj(x0)\n",
    "    its = 0\n",
    "    Opt = Float64[]\n",
    "    xkp = x0\n",
    "    for i in 1:maxIts\n",
    "        xk = xkp\n",
    "        fk, gk, Hk = obj(xk)\n",
    "        opt = norm(gk, 2)\n",
    "        push!(Opt, opt)\n",
    "        if opt < optTol*norm(g0)\n",
    "            break\n",
    "        end\n",
    "        if BkFlag == true\n",
    "            Bkinv = BkFunInv(Hk, 0.01)\n",
    "            dk = Bkinv * (- gk)\n",
    "        else\n",
    "            dk = Hk \\ (- gk)\n",
    "        end\n",
    "        if btFlag == true\n",
    "            αk = backTracking(obj, xk, dk, gk)\n",
    "        else\n",
    "            αk = 1\n",
    "        end\n",
    "        xkp = xk + αk * dk\n",
    "        its = its + 1\n",
    "    end\n",
    "    return xkp, its, Opt\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newtminBFGS (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function newtminBFGS(obj, x0; maxIts=1000, optTol=1e-6, btFlag=true)\n",
    "    # Minimize a function f using BFGS Newton’s method.\n",
    "    # obj: a function that evaluates the objective value,\n",
    "    # gradient, and Hessian at a point x, i.e.,\n",
    "    # (f, g, H) = obj(x)\n",
    "    # x0: starting point.\n",
    "    # maxIts (optional): maximum number of iterations.\n",
    "    # optTol (optional): optimality tolerance based on\n",
    "    # ||grad(x)|| <= optTol*||grad(x0)||\n",
    "    # btFlag (optional): true for doing Back Tracking\n",
    "    f0, g0, H0 = obj(x0)\n",
    "    D, V = eig(H0)\n",
    "    Hkp = V * Diagonal(map(x -> 1/max(x,1), D)) * V'\n",
    "    its = 0\n",
    "    Opt = Float64[]\n",
    "    xkp = copy(x0)\n",
    "    for i in 1:maxIts\n",
    "        xk = copy(xkp)\n",
    "        Hk = copy(Hkp)\n",
    "        gk = obj(xk)[2]\n",
    "        opt = norm(gk, 2)\n",
    "        push!(Opt, opt)\n",
    "        if opt < optTol*norm(g0)\n",
    "            break\n",
    "        end\n",
    "        dk = Hk * (- gk)\n",
    "        if btFlag == true\n",
    "            αk = backTracking(obj, xk, dk, gk)\n",
    "        else\n",
    "            αk = 1\n",
    "        end\n",
    "        xkp = xk + αk * dk\n",
    "        fkp, gkp, Hkp = obj(xkp)\n",
    "        sk = xkp - xk\n",
    "        yk = gkp - gk\n",
    "        ρk = 1/(yk' * sk)[]\n",
    "        Hkp = (eye(Hk) - ρk * sk * yk') * Hk * (eye(Hk) - ρk * yk * sk') + ρk * sk * sk'\n",
    "        its = its + 1\n",
    "    end\n",
    "    return xkp, its\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test()\n",
    "    \n",
    "    btFlag_v = Bool[0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    BkFlag_v = Bool[0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    @printf(\"%25s %26s %26s %6s\\n\",\n",
    "    \"-------Initial-------\",\"----------Newton----------\", \"----------BFGS----------\", \"--Win--\")\n",
    "    @printf(\"%3s %10s %10s %10s %10s %4s %10s %10s %4s\\n\",\n",
    "    \"No.\", \"f(x0)\",\"|∇f(x0)|\" ,\"f(x*)\",\"|∇f(x*)|\", \"Its\", \"f(x*)\",\"|∇f(x*)|\", \"Its\")\n",
    "    for i = 1:18\n",
    "    p = Problem(i)\n",
    "    pans = newtmin(p2obj(p), p.x0, maxIts = 1000, btFlag=btFlag_v[i], BkFlag=BkFlag_v[i])\n",
    "    pans_bfgs = newtminBFGS(p2obj(p), p.x0,  maxIts = 1000, btFlag=true)\n",
    "        @printf(\"%3i %10.2e %10.2e %10.2e %10.2e %4i %10.2e %10.2e %4i %7s\\n\",\n",
    "                i, p.obj(p.x0), norm(p.grd(p.x0)),\n",
    "                p.obj(pans[1]), norm(p.grd(pans[1])), pans[2],\n",
    "                p.obj(pans_bfgs[1]), norm(p.grd(pans_bfgs[1])), pans_bfgs[2],\n",
    "        ifelse( p.obj(pans[1]) < p.obj(pans_bfgs[1]), \"Newton\", \"BFGS\" )\n",
    "    )\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -------Initial------- ----------Newton----------   ----------BFGS---------- --Win--\n",
      "No.      f(x0)   |∇f(x0)|      f(x*)   |∇f(x*)|  Its      f(x*)   |∇f(x*)|  Its\n",
      "  1   2.50e+03   1.88e+03   4.10e-12   1.88e-05   32   7.86e-10   1.05e-03   25  Newton\n",
      "  2   7.79e-01   2.55e+00   2.73e-01   1.13e-01 1000   4.75e-13   8.98e-07  102    BFGS\n",
      "  3   3.89e-06   7.45e-03   1.13e-08   9.70e-11    2   1.13e-08   6.98e-11    4    BFGS\n",
      "  4   1.14e+00   2.00e+04   1.14e-05   2.00e-02  208   1.19e-11   6.81e-03  144    BFGS\n",
      "  5   1.03e+03   1.49e+02   4.95e-08   1.30e-04    7   1.44e-09   2.65e-05   60    BFGS\n",
      "  6   9.39e+10   1.01e+11   5.08e+03   6.78e+04   17   1.40e+08   5.81e+04   37  Newton\n",
      "  7   3.00e+01   1.78e+02   5.47e+00   1.81e+01 1000   6.21e-06   1.89e-05   70    BFGS\n",
      "  8   5.45e+09   8.02e+07   4.78e+01   7.40e+01   11   4.47e+01   7.04e+01   25    BFGS\n",
      "  9   2.87e+05   3.28e+05   8.81e+01   3.05e-01  228   8.81e+01   5.96e-01 1000  Newton\n",
      " 10   1.00e+12   2.00e+06   7.06e-25   1.68e-06    8   9.15e-19   1.31e-03   38  Newton\n",
      " 11   7.93e+06   2.14e+06   1.61e+06   4.88e+05 1000   8.58e+04   8.53e-01   19    BFGS\n",
      " 12   1.21e+01   3.97e+01   5.93e-05   4.40e-05 1000   1.87e-11   3.86e-05   30    BFGS\n",
      " 13   2.01e-03   5.30e-02   7.50e-08   4.22e-06 1000   3.95e-06   5.22e-08   53  Newton\n",
      " 14   4.84e+02   1.04e+03   4.12e+02   9.36e+02 1000   8.71e-08   9.55e-04  218    BFGS\n",
      " 15   3.23e+03   1.78e+03   1.78e+03   1.16e+03 1000   4.57e-06   9.33e-04  172    BFGS\n",
      " 16   1.42e+01   2.78e+01   4.78e-11   1.71e-05    4   8.51e-11   1.03e-05   11  Newton\n",
      " 17   1.92e+04   1.64e+04   1.24e-09   1.48e-03   37   5.67e-08   9.01e-03   79  Newton\n",
      " 18   1.39e-02   2.65e+00   8.39e-03   7.64e-01 1000   5.39e-03   9.31e-07  351    BFGS\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows that BFGS's performance is better than that of Newton method on Problem 2, 3, 4, 5, 7, 8, 11, 12, 14, 15 and 18.\n",
    "\n",
    "For Problem 3, 8 and 9, the objective values of both methods are actually very close. So for those Problem, both methods similar performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
